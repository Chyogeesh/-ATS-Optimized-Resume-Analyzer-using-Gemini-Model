from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from collections import Counter

def extract_keywords(text):
    """Extract keywords from the given text."""
    # Tokenization
    tokens = word_tokenize(text.lower())
    # Remove stop words and punctuation
    stop_words = set(stopwords.words('english'))
    keywords = [word for word in tokens if word.isalnum() and word not in stop_words]
    return keywords

def analyze_resume_vs_job(resume_text, job_description_text):
    """Analyze resume against job description and suggest missing keywords."""
    resume_keywords = extract_keywords(resume_text)
    job_description_keywords = extract_keywords(job_description_text)

    resume_keyword_count = Counter(resume_keywords)
    job_description_keyword_count = Counter(job_description_keywords)

    # Find missing keywords
    missing_keywords = job_description_keyword_count - resume_keyword_count
    return list(missing_keywords.keys())

# Example usage
missing_keywords = analyze_resume_vs_job(resume_text, job_description_text)
print("Missing Keywords:", missing_keywords)
